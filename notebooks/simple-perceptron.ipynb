{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1b5559c12f0>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting seeds\n",
    "np.random.seed(252)\n",
    "torch.manual_seed(252)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "class SimplePredictor(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.bn1 = nn.BatchNorm1d(num_hidden)\n",
    "        self.fn = nn.LeakyReLU()\n",
    "        self.d1 = nn.Dropout(0.4)\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fn(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for x, labels in loader:\n",
    "        x, labels = x.to(device), labels.to(device)\n",
    "        output = model(x)\n",
    "        pred = torch.round(output)\n",
    "        correct += torch.logical_and(pred.gt(labels.view_as(pred) - 0.1 * labels.view_as(pred)), pred.lt(labels.view_as(pred) + 0.1 * labels.view_as(pred))).sum().item()\n",
    "        total += x.shape[0]\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "data06 = pd.read_csv(\"../data/processed/target06.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "train_indices = np.random.rand(len(data06))>0.25\n",
    "\n",
    "numerical_data = torch.from_numpy(data06.values[train_indices,:-1]).float()\n",
    "targets = torch.from_numpy(data06.values[train_indices,-1]).float()\n",
    "test_numerical_data = torch.from_numpy(data06.values[~train_indices,:-1]).float()\n",
    "test_targets = torch.from_numpy(data06.values[~train_indices,-1]).float()\n",
    "\n",
    "train_dataset = data.TensorDataset(numerical_data, targets)\n",
    "test_dataset = data.TensorDataset(test_numerical_data, test_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimplePredictor(\n",
      "  (linear1): Linear(in_features=8, out_features=128, bias=True)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fn): LeakyReLU(negative_slope=0.01)\n",
      "  (d1): Dropout(p=0.4, inplace=False)\n",
      "  (linear2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimplePredictor(num_inputs=8, num_hidden=128, num_outputs=1)\n",
    "model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "loss_fun = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 5.87e+02\n",
      "Epoch: 1, loss: 7.28e+02\n",
      "Epoch: 2, loss: 7.34e+02\n",
      "Epoch: 3, loss: 6.84e+02\n",
      "Epoch: 4, loss: 6.94e+02\n",
      "Epoch: 5, loss: 6.43e+02\n",
      "Epoch: 6, loss: 6.99e+02\n",
      "Epoch: 7, loss: 6.73e+02\n",
      "Epoch: 8, loss: 5.84e+02\n",
      "Epoch: 9, loss: 6.83e+02\n",
      "Epoch: 10, loss: 5.39e+02\n",
      "Epoch: 11, loss: 5.08e+02\n",
      "Epoch: 12, loss: 5.53e+02\n",
      "Epoch: 13, loss: 4.9e+02\n",
      "Epoch: 14, loss: 6.37e+02\n",
      "Epoch: 15, loss: 4.85e+02\n",
      "Epoch: 16, loss: 4.3e+02\n",
      "Epoch: 17, loss: 6.83e+02\n",
      "Epoch: 18, loss: 5.27e+02\n",
      "Epoch: 19, loss: 5.72e+02\n",
      "Epoch: 20, loss: 6.14e+02\n",
      "Epoch: 21, loss: 6.89e+02\n",
      "Epoch: 22, loss: 5.85e+02\n",
      "Epoch: 23, loss: 4.29e+02\n",
      "Epoch: 24, loss: 5.1e+02\n",
      "Epoch: 25, loss: 5.28e+02\n",
      "Epoch: 26, loss: 5.09e+02\n",
      "Epoch: 27, loss: 5.57e+02\n",
      "Epoch: 28, loss: 4.18e+02\n",
      "Epoch: 29, loss: 4.39e+02\n",
      "Epoch: 30, loss: 5.15e+02\n",
      "Epoch: 31, loss: 4.71e+02\n",
      "Epoch: 32, loss: 4.33e+02\n",
      "Epoch: 33, loss: 3.59e+02\n",
      "Epoch: 34, loss: 4.12e+02\n",
      "Epoch: 35, loss: 3.97e+02\n",
      "Epoch: 36, loss: 3.62e+02\n",
      "Epoch: 37, loss: 4.63e+02\n",
      "Epoch: 38, loss: 3.85e+02\n",
      "Epoch: 39, loss: 3.75e+02\n",
      "Epoch: 40, loss: 2.95e+02\n",
      "Epoch: 41, loss: 3.71e+02\n",
      "Epoch: 42, loss: 3.95e+02\n",
      "Epoch: 43, loss: 2.79e+02\n",
      "Epoch: 44, loss: 2.76e+02\n",
      "Epoch: 45, loss: 3.04e+02\n",
      "Epoch: 46, loss: 4.08e+02\n",
      "Epoch: 47, loss: 3.08e+02\n",
      "Epoch: 48, loss: 3.11e+02\n",
      "Epoch: 49, loss: 2.97e+02\n",
      "Epoch: 50, loss: 2.25e+02\n",
      "Epoch: 51, loss: 2.06e+02\n",
      "Epoch: 52, loss: 2.54e+02\n",
      "Epoch: 53, loss: 2.9e+02\n",
      "Epoch: 54, loss: 2.46e+02\n",
      "Epoch: 55, loss: 1.86e+02\n",
      "Epoch: 56, loss: 2.15e+02\n",
      "Epoch: 57, loss: 2.87e+02\n",
      "Epoch: 58, loss: 1.59e+02\n",
      "Epoch: 59, loss: 2.28e+02\n",
      "Epoch: 60, loss: 2.17e+02\n",
      "Epoch: 61, loss: 3.01e+02\n",
      "Epoch: 62, loss: 2.63e+02\n",
      "Epoch: 63, loss: 2.21e+02\n",
      "Epoch: 64, loss: 2.47e+02\n",
      "Epoch: 65, loss: 2.32e+02\n",
      "Epoch: 66, loss: 2.41e+02\n",
      "Epoch: 67, loss: 1.98e+02\n",
      "Epoch: 68, loss: 1.84e+02\n",
      "Epoch: 69, loss: 2e+02\n",
      "Epoch: 70, loss: 2.98e+02\n",
      "Epoch: 71, loss: 3.17e+02\n",
      "Epoch: 72, loss: 2.25e+02\n",
      "Epoch: 73, loss: 1.55e+02\n",
      "Epoch: 74, loss: 2.38e+02\n",
      "Epoch: 75, loss: 1.82e+02\n",
      "Epoch: 76, loss: 1.54e+02\n",
      "Epoch: 77, loss: 1.4e+02\n",
      "Epoch: 78, loss: 2.83e+02\n",
      "Epoch: 79, loss: 2.14e+02\n",
      "Epoch: 80, loss: 2.24e+02\n",
      "Epoch: 81, loss: 1.46e+02\n",
      "Epoch: 82, loss: 1.01e+02\n",
      "Epoch: 83, loss: 2.28e+02\n",
      "Epoch: 84, loss: 2.18e+02\n",
      "Epoch: 85, loss: 1.6e+02\n",
      "Epoch: 86, loss: 1.74e+02\n",
      "Epoch: 87, loss: 1.49e+02\n",
      "Epoch: 88, loss: 1.98e+02\n",
      "Epoch: 89, loss: 1.06e+02\n",
      "Epoch: 90, loss: 1.22e+02\n",
      "Epoch: 91, loss: 1.99e+02\n",
      "Epoch: 92, loss: 1.5e+02\n",
      "Epoch: 93, loss: 2.42e+02\n",
      "Epoch: 94, loss: 1.66e+02\n",
      "Epoch: 95, loss: 94.7\n",
      "Epoch: 96, loss: 1.19e+02\n",
      "Epoch: 97, loss: 1.13e+02\n",
      "Epoch: 98, loss: 1.52e+02\n",
      "Epoch: 99, loss: 88.1\n",
      "Epoch: 100, loss: 1.4e+02\n",
      "Epoch: 101, loss: 1.14e+02\n",
      "Epoch: 102, loss: 1.17e+02\n",
      "Epoch: 103, loss: 1.47e+02\n",
      "Epoch: 104, loss: 1.29e+02\n",
      "Epoch: 105, loss: 1.17e+02\n",
      "Epoch: 106, loss: 80.8\n",
      "Epoch: 107, loss: 1.19e+02\n",
      "Epoch: 108, loss: 1.09e+02\n",
      "Epoch: 109, loss: 92.0\n",
      "Epoch: 110, loss: 1.47e+02\n",
      "Epoch: 111, loss: 1.12e+02\n",
      "Epoch: 112, loss: 83.8\n",
      "Epoch: 113, loss: 1.86e+02\n",
      "Epoch: 114, loss: 82.3\n",
      "Epoch: 115, loss: 56.1\n",
      "Epoch: 116, loss: 1e+02\n",
      "Epoch: 117, loss: 91.5\n",
      "Epoch: 118, loss: 1.24e+02\n",
      "Epoch: 119, loss: 1.23e+02\n",
      "Epoch: 120, loss: 92.9\n",
      "Epoch: 121, loss: 1.32e+02\n",
      "Epoch: 122, loss: 1.21e+02\n",
      "Epoch: 123, loss: 1.65e+02\n",
      "Epoch: 124, loss: 1.93e+02\n",
      "Epoch: 125, loss: 1.32e+02\n",
      "Epoch: 126, loss: 1.18e+02\n",
      "Epoch: 127, loss: 73.1\n",
      "Epoch: 128, loss: 1.71e+02\n",
      "Epoch: 129, loss: 1.43e+02\n",
      "Epoch: 130, loss: 93.0\n",
      "Epoch: 131, loss: 86.1\n",
      "Epoch: 132, loss: 1.18e+02\n",
      "Epoch: 133, loss: 1.08e+02\n",
      "Epoch: 134, loss: 95.6\n",
      "Epoch: 135, loss: 82.2\n",
      "Epoch: 136, loss: 97.8\n",
      "Epoch: 137, loss: 1.11e+02\n",
      "Epoch: 138, loss: 59.9\n",
      "Epoch: 139, loss: 1.18e+02\n",
      "Epoch: 140, loss: 1.58e+02\n",
      "Epoch: 141, loss: 85.1\n",
      "Epoch: 142, loss: 1.51e+02\n",
      "Epoch: 143, loss: 97.8\n",
      "Epoch: 144, loss: 93.8\n",
      "Epoch: 145, loss: 1.06e+02\n",
      "Epoch: 146, loss: 97.4\n",
      "Epoch: 147, loss: 84.5\n",
      "Epoch: 148, loss: 77.1\n",
      "Epoch: 149, loss: 69.7\n",
      "Epoch: 150, loss: 1.02e+02\n",
      "Epoch: 151, loss: 98.5\n",
      "Epoch: 152, loss: 1.06e+02\n",
      "Epoch: 153, loss: 80.9\n",
      "Epoch: 154, loss: 85.1\n",
      "Epoch: 155, loss: 1.06e+02\n",
      "Epoch: 156, loss: 98.6\n",
      "Epoch: 157, loss: 1.08e+02\n",
      "Epoch: 158, loss: 1.44e+02\n",
      "Epoch: 159, loss: 1.45e+02\n",
      "Epoch: 160, loss: 78.4\n",
      "Epoch: 161, loss: 1.29e+02\n",
      "Epoch: 162, loss: 1.49e+02\n",
      "Epoch: 163, loss: 90.1\n",
      "Epoch: 164, loss: 80.9\n",
      "Epoch: 165, loss: 1.48e+02\n",
      "Epoch: 166, loss: 1.1e+02\n",
      "Epoch: 167, loss: 1.04e+02\n",
      "Epoch: 168, loss: 1.48e+02\n",
      "Epoch: 169, loss: 1.15e+02\n",
      "Epoch: 170, loss: 79.7\n",
      "Epoch: 171, loss: 1.05e+02\n",
      "Epoch: 172, loss: 1.65e+02\n",
      "Epoch: 173, loss: 1.05e+02\n",
      "Epoch: 174, loss: 56.6\n",
      "Epoch: 175, loss: 71.2\n",
      "Epoch: 176, loss: 1.11e+02\n",
      "Epoch: 177, loss: 1.17e+02\n",
      "Epoch: 178, loss: 73.6\n",
      "Epoch: 179, loss: 1.68e+02\n",
      "Epoch: 180, loss: 1.13e+02\n",
      "Epoch: 181, loss: 84.6\n",
      "Epoch: 182, loss: 71.6\n",
      "Epoch: 183, loss: 78.2\n",
      "Epoch: 184, loss: 1.2e+02\n",
      "Epoch: 185, loss: 77.5\n",
      "Epoch: 186, loss: 72.0\n",
      "Epoch: 187, loss: 1.02e+02\n",
      "Epoch: 188, loss: 98.8\n",
      "Epoch: 189, loss: 71.4\n",
      "Epoch: 190, loss: 1.35e+02\n",
      "Epoch: 191, loss: 1.3e+02\n",
      "Epoch: 192, loss: 89.7\n",
      "Epoch: 193, loss: 1.03e+02\n",
      "Epoch: 194, loss: 95.4\n",
      "Epoch: 195, loss: 98.0\n",
      "Epoch: 196, loss: 1.4e+02\n",
      "Epoch: 197, loss: 1.66e+02\n",
      "Epoch: 198, loss: 1.65e+02\n",
      "Epoch: 199, loss: 1.11e+02\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for data_inputs, data_labels in data_loader:\n",
    "        data_inputs = data_inputs.to(device)\n",
    "        data_labels = data_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(data_inputs).squeeze(dim=1)\n",
    "        loss = loss_fun(preds, data_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2008025929927458"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, test_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 20.9200,  22.6400,  11.9000,  27.8100,  25.5600,  22.8000,  18.8400,\n         39.7800,  10.4100,  24.0900,  46.9900,   7.1000,  37.1800,   8.7000,\n          9.7700,  18.6300,   7.0700,  25.3200,  15.0900,  10.6400,  31.9500,\n         27.9700,   8.0300,  45.4600,  15.8300,  53.5600,   8.8700,  15.4200,\n         14.8400,   9.9000,  19.3600,  10.2800,  21.1100,  49.6700,  11.1900,\n         12.2700,   8.0100,  41.5700,  21.5400,   4.7500,  28.4000,   5.0600,\n         13.1200,   5.5200,  16.7900,  54.8300,  23.3800,   4.0500,  11.1900,\n         25.8400,  58.3900,  10.2500,  22.5100,  29.4600,  15.9800,   6.9600,\n         17.1900,   9.2800,  20.0400,  17.6500,  21.8200,  24.0700,  13.7700,\n         11.5100,  30.2600,  25.2100,  11.4300,   9.4700,  12.5200,  17.9700,\n         11.2400,  59.2900,  21.3200,  14.9300,  17.9600,  14.1600,  19.8900,\n         17.3700,  25.7400,  18.8300,  25.0100,   8.9900,  16.7800,  15.8400,\n         29.3700,  15.2700,  33.8300,  22.3900,  12.2700,  17.8800,  24.3800,\n         20.8100,  10.2400,   3.5000,  26.8000,  17.8600,  18.6100,  18.7800,\n         21.6100,  45.5700,  13.1200,  18.4600,  38.8500,  64.4900,  31.1700,\n          8.6900,   6.1900,   7.0200,  12.5900,  15.9600,  25.5800,  14.2400,\n         24.2400,  21.4500,  10.1200,  10.5900, 102.4400,  33.3900,  17.0600,\n          9.4100,   8.2400,  15.6500,  30.7600,  13.0400,   2.8600,  17.5000,\n          9.5000,   9.2800], device='cuda:0')"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 18.9709,  49.6116,   8.1770,  14.2525,  20.7363,  14.5305,  27.4487,\n         24.2884,  12.4430,  14.1497,  21.1399,  14.4776,  39.7353,   8.2929,\n         18.3694,  14.2637,  12.8021,  33.2520,  21.1720,  12.1356,  33.2720,\n         18.5826,  15.4705,  32.2479,  16.1407,  48.9864,  22.3402,  11.1683,\n         17.1737,  13.1919,  14.0843,  23.6869,  17.2599,  24.0692,  23.4664,\n         15.0107,   7.5973,  34.4271,  16.2389,  10.7882,  16.7696,   6.5953,\n         39.2492,  20.7286,  10.2109,  36.8062,   8.3447,   9.7610,  13.4944,\n         21.3061,   8.5721,  14.2382,  21.2795,  37.4153,   8.8329,  10.6365,\n         18.7296,  15.6151,   7.9315,  15.4716,  14.6352,   9.4295,  13.4242,\n          8.5209,  22.3609,  26.1189,  14.0130,  17.2038,  13.3810,  11.8236,\n         17.5076,  59.2773,  43.5502,  22.5803,  19.3706,  13.3424,  17.6790,\n         17.3370,  18.1210,   9.5628,  28.7828,  14.1420,  17.7311,  23.9240,\n         40.9087,  23.1944,  11.4875,  20.1528,  20.8879,  16.6871,  15.1492,\n         24.9869,  16.2455,  12.3629,  21.8241,  15.7270,  17.0218,  30.1671,\n         34.1468,  21.2922,   8.8845,  21.7091,  38.4707,  40.3677,  38.8882,\n          8.7118,  11.2998,  18.3992,  15.7893,  15.3906,  22.9551,  17.4429,\n         17.7916,  22.5962,  15.1099,  13.4186, 104.8057,  31.5005,  15.8831,\n         39.8216,  16.0971,  12.6193,  23.0429,  20.0544,  10.7432,  26.1390,\n         20.4707,  15.0634], device='cuda:0', grad_fn=<SqueezeBackward1>)"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}