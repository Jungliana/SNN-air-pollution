{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import snntorch as snn\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2351cb572b0>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting seeds\n",
    "np.random.seed(445)\n",
    "torch.manual_seed(445)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class SimpleSNNPredictor(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, beta=0.95, num_steps=25):\n",
    "        super().__init__()\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dtype = torch.float\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ =model(data.view(batch_size, -1))\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "data06 = pd.read_csv(\"../data/processed/target06.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "all_data = data.TensorDataset(torch.from_numpy((data06.values[:,:-1] - data06.values[:,:-1].min(0)) / data06.values[:,:-1].ptp(0)).float(), torch.from_numpy(data06.values[:,-1]).float())  # with normalization\n",
    "train_dataset, test_dataset, valid_dataset = torch.utils.data.random_split(all_data, (round(0.7 * len(all_data)), round(0.2 * len(all_data)), round(0.1 * len(all_data))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)\n",
    "valid_loader = data.DataLoader(valid_dataset, batch_size=128, shuffle=False, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleSNNPredictor(\n",
      "  (fc1): Linear(in_features=8, out_features=1000, bias=True)\n",
      "  (lif1): Leaky()\n",
      "  (fc2): Linear(in_features=1000, out_features=150, bias=True)\n",
      "  (lif2): Leaky()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_inputs=8\n",
    "num_hidden=1000\n",
    "num_outputs=150\n",
    "\n",
    "model = SimpleSNNPredictor(num_inputs, num_hidden, num_outputs)\n",
    "model.to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=6e-4, betas=(0.9, 0.999))\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epochs = 1\n",
    "num_steps = 20\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0\n",
      "Train Set Loss: 110.53\n",
      "Test Set Loss: 97.94\n",
      "Train set accuracy for a single minibatch: 3.91%\n",
      "Test set accuracy for a single minibatch: 7.03%\n",
      "\n",
      "\n",
      "Epoch 1, Iteration 3\n",
      "Train Set Loss: 77.12\n",
      "Test Set Loss: 78.19\n",
      "Train set accuracy for a single minibatch: 10.16%\n",
      "Test set accuracy for a single minibatch: 3.91%\n",
      "\n",
      "\n",
      "Epoch 2, Iteration 6\n",
      "Train Set Loss: 74.85\n",
      "Test Set Loss: 75.76\n",
      "Train set accuracy for a single minibatch: 9.38%\n",
      "Test set accuracy for a single minibatch: 6.25%\n",
      "\n",
      "\n",
      "Epoch 3, Iteration 9\n",
      "Train Set Loss: 72.22\n",
      "Test Set Loss: 76.88\n",
      "Train set accuracy for a single minibatch: 9.38%\n",
      "Test set accuracy for a single minibatch: 5.47%\n",
      "\n",
      "\n",
      "Epoch 4, Iteration 12\n",
      "Train Set Loss: 73.23\n",
      "Test Set Loss: 77.51\n",
      "Train set accuracy for a single minibatch: 10.16%\n",
      "Test set accuracy for a single minibatch: 7.81%\n",
      "\n",
      "\n",
      "Epoch 5, Iteration 15\n",
      "Train Set Loss: 72.87\n",
      "Test Set Loss: 80.81\n",
      "Train set accuracy for a single minibatch: 8.59%\n",
      "Test set accuracy for a single minibatch: 5.47%\n",
      "\n",
      "\n",
      "Epoch 6, Iteration 18\n",
      "Train Set Loss: 70.91\n",
      "Test Set Loss: 77.62\n",
      "Train set accuracy for a single minibatch: 6.25%\n",
      "Test set accuracy for a single minibatch: 8.59%\n",
      "\n",
      "\n",
      "Epoch 7, Iteration 21\n",
      "Train Set Loss: 74.71\n",
      "Test Set Loss: 78.99\n",
      "Train set accuracy for a single minibatch: 7.81%\n",
      "Test set accuracy for a single minibatch: 7.81%\n",
      "\n",
      "\n",
      "Epoch 8, Iteration 24\n",
      "Train Set Loss: 74.04\n",
      "Test Set Loss: 76.86\n",
      "Train set accuracy for a single minibatch: 5.47%\n",
      "Test set accuracy for a single minibatch: 3.12%\n",
      "\n",
      "\n",
      "Epoch 9, Iteration 27\n",
      "Train Set Loss: 70.85\n",
      "Test Set Loss: 78.33\n",
      "Train set accuracy for a single minibatch: 5.47%\n",
      "Test set accuracy for a single minibatch: 3.91%\n",
      "\n",
      "\n",
      "Epoch 10, Iteration 30\n",
      "Train Set Loss: 70.16\n",
      "Test Set Loss: 76.99\n",
      "Train set accuracy for a single minibatch: 7.03%\n",
      "Test set accuracy for a single minibatch: 4.69%\n",
      "\n",
      "\n",
      "Epoch 11, Iteration 33\n",
      "Train Set Loss: 73.76\n",
      "Test Set Loss: 76.06\n",
      "Train set accuracy for a single minibatch: 5.47%\n",
      "Test set accuracy for a single minibatch: 5.47%\n",
      "\n",
      "\n",
      "Epoch 12, Iteration 36\n",
      "Train Set Loss: 70.38\n",
      "Test Set Loss: 77.49\n",
      "Train set accuracy for a single minibatch: 3.12%\n",
      "Test set accuracy for a single minibatch: 4.69%\n",
      "\n",
      "\n",
      "Epoch 13, Iteration 39\n",
      "Train Set Loss: 70.55\n",
      "Test Set Loss: 78.14\n",
      "Train set accuracy for a single minibatch: 6.25%\n",
      "Test set accuracy for a single minibatch: 3.12%\n",
      "\n",
      "\n",
      "Epoch 14, Iteration 42\n",
      "Train Set Loss: 70.52\n",
      "Test Set Loss: 76.51\n",
      "Train set accuracy for a single minibatch: 7.81%\n",
      "Test set accuracy for a single minibatch: 6.25%\n",
      "\n",
      "\n",
      "Epoch 15, Iteration 45\n",
      "Train Set Loss: 71.52\n",
      "Test Set Loss: 77.70\n",
      "Train set accuracy for a single minibatch: 3.12%\n",
      "Test set accuracy for a single minibatch: 5.47%\n",
      "\n",
      "\n",
      "Epoch 17, Iteration 1\n",
      "Train Set Loss: 68.51\n",
      "Test Set Loss: 76.39\n",
      "Train set accuracy for a single minibatch: 2.34%\n",
      "Test set accuracy for a single minibatch: 3.12%\n",
      "\n",
      "\n",
      "Epoch 18, Iteration 4\n",
      "Train Set Loss: 67.99\n",
      "Test Set Loss: 76.97\n",
      "Train set accuracy for a single minibatch: 12.50%\n",
      "Test set accuracy for a single minibatch: 3.91%\n",
      "\n",
      "\n",
      "Epoch 19, Iteration 7\n",
      "Train Set Loss: 69.40\n",
      "Test Set Loss: 76.73\n",
      "Train set accuracy for a single minibatch: 4.69%\n",
      "Test set accuracy for a single minibatch: 4.69%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.round().type(torch.LongTensor).to(device)\n",
    "\n",
    "    # forward pass\n",
    "        model.train()\n",
    "        spk_rec, mem_rec = model(data.view(batch_size, -1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros(1, dtype=dtype, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.round().type(torch.LongTensor).to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = model(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros(1, dtype=dtype, device=device)\n",
    "            for step in range(num_steps):\n",
    "                test_loss += loss(test_mem[step], test_targets)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer()\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([-89.9639,   7.9948,   6.4838,   7.9867,  12.5874, -41.4855, -15.5760,\n         11.4371, -44.0091,   0.6600, -13.6747,  -5.2879,   0.3238, -44.4139,\n        -54.6852, -49.0480,   7.6722, -79.1993, -25.6788,  12.2297,   8.6836,\n        -35.4031, -23.9025, -47.6584, -30.4154, -10.5103,   5.9806, -46.8056,\n        -32.0493,   6.6479,  -2.9635,  11.3102, -69.8873,  -2.1698,   8.0040,\n          8.8136, -19.6020,   2.1339, -13.5232, -36.1154, -23.4889, -18.5171,\n        -45.0278, -45.0049, -43.8459,  11.5084,  -7.0310,  13.7153,  -1.1603,\n        -49.8283,   7.7661,   2.9539, -10.6930, -65.5782,  12.5545, -45.2888,\n         13.5379,   9.5674, -48.5092,  10.5516, -59.3391,   7.7039,  15.4329,\n         12.8692, -58.3383, -13.7325,  10.8780,  11.4188, -28.0685, -27.4100,\n          5.6322, -52.1165,   0.5348,   9.8030,   4.3293, -24.6781, -83.0302,\n        -27.0966, -26.4096, -15.6699, -82.9912,  12.1810,   5.5019, -12.0608,\n         -9.9057,  -6.7921, -24.6250,  -9.7313, -22.8599,  11.1837, -64.9285,\n          1.2051,   1.0463, -54.9992,   9.5048,   0.1954,   4.4794,   4.3752,\n        -33.1432, -60.8653, -70.7145, -15.8474, -85.7680,  -0.8745,  11.5111,\n        -61.9646, -57.8927, -12.1437, -48.4732,  16.6014, -19.3582,  10.8957,\n        -21.7732, -55.5685,   9.9742, -37.5543, -23.1463,  10.8992,   8.8580,\n        -19.0483,   1.4292,   3.9607, -88.5612,  14.6315, -67.7077,  -8.4292,\n          9.4922, -55.1167], device='cuda:0'),\nindices=tensor([16, 14, 18, 12, 16, 16, 10,  8, 11, 21,  8, 14, 10, 36, 36, 24, 14, 54,\n        14, 13, 10, 26, 21, 16, 15,  8, 13, 34, 26, 10, 16, 14, 20,  8,  8, 11,\n         8, 15, 11, 24, 13, 15, 18, 11, 16, 16, 10, 11,  8, 13, 16, 11,  7, 89,\n        11, 45, 10, 10, 47,  8, 13,  8, 11, 10, 10, 13, 11,  8, 10, 31, 13, 95,\n        18, 14, 11, 16, 28, 47, 14, 16, 11,  8,  8,  8, 24, 13, 21, 23,  3, 16,\n        27, 16, 10, 32, 10,  8, 10,  8, 12, 47, 24,  8, 16, 14, 16, 54, 16, 16,\n        27, 10,  8, 10, 10, 31,  8, 22, 18, 14, 10, 16, 14, 16, 51, 10, 14,  5,\n        10, 18], device='cuda:0'))"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mem.sum(dim=0).max(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([49, 18, 16, 55, 11, 25,  9, 15, 10, 21, 15, 17,  9, 35, 12, 12, 10, 26,\n        17, 12,  6, 25, 15, 20, 27,  5, 17, 33, 15, 12,  9, 22, 65,  7,  5, 17,\n        12, 21, 11, 55, 23, 16, 19, 14,  9, 14, 13, 13, 13, 26, 12,  9, 10, 65,\n        15, 54, 20, 13, 21,  6, 15,  9, 23, 11, 32, 12,  6,  9, 32, 29, 18, 98,\n        29, 25, 12,  7, 25, 32, 16, 10, 11, 12,  9,  5, 33, 32, 25, 10,  3,  8,\n        64, 17, 17, 30, 12, 15, 14,  9, 16, 47, 29, 22, 25, 68, 18, 10, 24, 13,\n        17, 10, 16, 16, 10, 29, 11, 35, 14, 10, 12, 16, 14, 14, 44,  9, 32, 14,\n        15, 14], device='cuda:0')"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}